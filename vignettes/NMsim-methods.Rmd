---
title: "NMsim - Additional Simulation Methods"
output:
rmarkdown::html_vignette:
    toc: true
    code_folding: show
Suggests: markdown
VignetteBuilder: knitr
vignette: >
  %\VignetteIndexEntry{Simulation Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
- \usepackage{ae}
---

```{r,include = FALSE}
##knitr::opts_chunk$set(dev = "cairo_pdf")
knitr::opts_chunk$set(
                      collapse = TRUE
                     ,comment = "#>"
                     ,fig.width=7
                     ,cache=FALSE
                  )

## this changes data.table syntax. I think we can do without.
## knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

```{r,setup,include=F}
## library(devtools)
## unloadNamespace("NMsim")
## unloadNamespace("NMdata")

## load_all("~/wdirs/NMdata")
## load_all()
library(NMsim)
library(data.table)
library(NMdata)
library(dplyr)
library(tibble)
library(ggplot2)
library(patchwork)
library(tracee)
library(tidyr)
library(fst)
library(knitr)
## NMdataConf(path.nonmem="/opt/NONMEM/nm75/run/nmfe75")
## NMdataConf(path.nonmem="/opt/nonmem/nm751/run/nmfe75")
## NMdataConf(dir.psn=NULL)

theme_set(theme_bw())
this.script <- "NMsim-methods.Rmd"
writeOutput <- TRUE
file.project <- function(...)file.path(system.file("examples",package="NMsim"),...)
## file.project <- function(...)file.path("../inst/examples",...)
## file.project <- function(...)file.path("~/wdirs/NMsim/inst/examples",...)

found.files <- list.files(file.project("nonmem/NMsim"),pattern="noname\\.(lst|xml|ext|cov|cor|coi|phi|msf|msfi|msfo|tab)",full.names=TRUE)
unlink(found.files)

run.simuls <- FALSE
NMdataConf(as.fun="data.table")

dat.sim <- read_fst("simulate-results/dat_sim.fst",as.data.table=TRUE)
```


Built `r Sys.Date()` using NMsim `r packageVersion("NMsim")`.


## Objectives
This vignettes aims at enabling you to use `NMsim` for the following purposes

* Simulation of typical subjects, 
* Simualation of known subjects (estimated random effects), 
* Simulation with parameter uncertainty
  - By sampling for a successful covariance step
  - By using models from bootstrap sampling
* Simulation with parameters modified from the estimated values

## Prerequisites
You should have configured `NMsim` with the path to the Nonmem
installation and maybe also PSN. See
[`NMsim-config.html`](https://philipdelff.github.io/NMsim/articles/NMsim-config.html). Don't
worry - it is very easy. 

You should be familiar with basic `NMsim` arguments as described in [`NMsim-basics.html`](https://philipdelff.github.io/NMsim/articles/NMsim-basics.html). In that vignette you should have learned to use the default simulation method. This vignette will be using the same model and simulation input data as in [`NMsim-basics.html`](https://philipdelff.github.io/NMsim/articles/NMsim-basics.html) to demonstrate how to use additional methods and features of `NMsim`.

```{r}
file.mod <- file.project("nonmem/xgxr021.mod")
```

## Simulation of a typical subject
A typical subject is here understood as a subject without random
effects, i.e. all ETA's equal zero. It is important to realize that
"typical" does not have to do with covariates which the user will
still need to control in the model, in the simulation input data, or
by a combination of these. Getting `NMsim` to run with all ETA's
equaling zero is this easy:

```{r,eval=FALSE}
simres.typ <- NMsim(file.mod=file.mod,
                    data=dat.sim,
                    name.sim="typSubj",
                    method.sim=NMsim_typical)

```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_typ.fst"
if(run.simuls){
    write_fst(simres.typ,path=file.fst)
} else {
    simres.typ <- read_fst(file.fst,as.data.table=TRUE)
}
```


In the first simulation we used `PRED` from the default simulation
method to get a typical subject simulation. That will work in many
cases, but that depends on the model. The way to run a simulation with
all ETA's set to 0 is using `method.sim=NMsim_typical`.

```{r,eval=TRUE}
p.typ <- ggplot(simres.typ,aes(TIME,IPRED,color=trt))+geom_line()+
    geom_line(aes(y=PRED))
p.typ

```

## Simulation of known subjects
We sometimes want to simulate the already observed subjects. This means we want to reuse the estimated random effects (ETA's) given the subject ID's. `NMsim` has a method for this. The restriction is that all subjects (values of `ID`) in the simulation input data must have been used in the estimation input data.

```{r,eval=FALSE}
## read model results just to extract the observed ID's
res.mod <- NMscanData(file.mod,quiet=TRUE)
ids <- data.frame(ID=unique(res.mod$ID))

## Repeat the simulation data set for each ID and order accordingly
dat.sim.known <- merge(ids,
                       dat.sim[,setdiff(colnames(base.sim.known),c("ID")),with=FALSE]
                       )
setorder(dat.sim.known,ID,TIME,EVID)
## check data
NMcheckData(dat.sim.known,type.data="sim")

simres.known <- NMsim(file.mod=file.mod,
                      data=dat.sim.known,
                      name.sim="known1",
                      text.table="PRED IPRED CL V2 KA"
                     ,method.sim=NMsim_known
                      )
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_known.fst"
if(run.simuls){
    write_fst(simres.known,path=file.fst)
} else {
    simres.known <- read_fst(file.fst,as.data.table=TRUE)
}
```

And the simulation results are plotted for each subject.
```{r,eval=TRUE}
ggplot(as.data.table(simres.known)[EVID==2],aes(TIME,IPRED,colour=factor(ID)))+
    geom_line()+
    theme(legend.position="none")
```

<!-- Show a plot of the individual parameters in estimate and in sim -->

### Known subjects: Simulate individual PK at PD sampling times for a PK/PD dataset
We also connected some PK data. We want to plot the PD data angainst
PK. However, PD was sampled differnetly than PK, and we want to
evaluate the individual predictions of the PK model at the individual
PD samplng times.

Currently, there is no PD data in the example data used to build this
vignette. For a PK model without time-varying covariates, the steps to
to generate the data for the simulation are:

```{r,pddata,include=FALSE,eval=TRUE}
pd <- readRDS(file.project("data/xgxr_pd.rds")) |> as.data.table()
```

* Take dose records from PK model estimation input data (`pkdos`). Just keep necessary columns like `ID`, `TIME`, `EVID`, `CMT`, `AMT`, `ADDL`, `II`, and any necessary covariates
* Take PD data observation records (`pdsamples`). Just keep `ID`, `TIME`, and set `EVID=2`.
* Add a unique row identifier to `pdsamples` (an integer row counter, like `ROW=1:nrow(pdsamples)`)
* Stack (`rbind` for data.tables or `bind_rows` in tidyverse) `pkdos` and `pdsamples` to one data set (`pdsim`)
* In `pdsim`, set `DV=NA`
* Sort `pdsim` at least by `ID`, `TIME` and `EVID`. There could be more depending on trial design

In case of time-varying covariates, you can keep all data records from the PK data (without `DV`), but change observation records to simulation records (`EVID=2` instead of `EVID=0`).

```{r,known-pkpd,eval=TRUE}
## Take dose records from PK model estimation input data
pkres <- NMscanData(file.mod,quiet=TRUE)
pkdos <- pkres[EVID==1,.(ID, TIME, EVID, CMT, AMT)]
## Take PD data observation records (`pdsamples`)
pd[,ROWPD:=.I]
pdsamples <- pd[EVID==0,.(ROWPD,ID,TIME,EVID=2)]
## Stack `pkdos` and `pdsamples` to one data set (`pdsim`)
pdsim <- rbind(pkdos,pdsamples,fill=TRUE)
pdsim[,DV:=NA]
pdsim <- pdsim[ID%in%pkres$ID]
setorder(pdsim,ID,TIME,EVID)
```

Then run `NMsim` like this:

```{r,known-pkpd-run,eval=FALSE}

simres.pksim <- NMsim(file.mod,
                      data=pdsim,
                      name.sim="pkpd",
                     ,method.sim=NMsim_known
                     ,text.table="IPRED PRED"
                      )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_pksim.fst"
if(run.simuls){
    write_fst(simres.pksim,path=file.fst)
} else {
    simres.pksim <- read_fst(file.fst,as.data.table=TRUE)
}
```


Now rename `res.pksim$IPRED` to something meaningfull like `res.pksim$PKIPRED`, and you can merge `res.pksim` onto the PD data by the unique row identifier. 

```{r,merge-pdres,eval=TRUE}
setnames(simres.pksim,"IPRED","PKIPRED")
pd2 <- mergeCheck(pd,simres.pksim[,.(ROWPD,PKIPRED)],by="ROWPD",all.x=TRUE)
```

```{r,eval=TRUE}
ggplot(pd2[!is.na(LIDV)&!is.na(PKIPRED)],aes(PKIPRED,LIDV))+
    geom_point()+
    labs(x="Individual PK prediction",y="Observed PD value") ## +
``` 


## Simulation of parameter uncertainty
We already saw how `NMsim` can easily be used to generate new subjects
(for say prediction intervals) by using the between-subject and
between-occasion variability as described by the model. We may also
want to simulate the uncertainty of the parameter estimates (for say
confidence intervals). `NMsim` supports two different approaches to
this. 

* Simulation based on the estimated variance-covariance matrix of the
parameters as estimated by a successful `$COVARIANCE` step in Nonmem.

* Simulation based on a bootstrap of the model. `NMsim` does not
provide functions to run the bootstrap, but it can use the results
of sampled models, like what is generated by `PSN`'s bootstrap
function.

It is beyond the scope of this vignette to describe the pros and cons
of those two approaches. The following examples serve to exlain the
preequisites for using `NMsim` to do it, and obviously how to get
`NMsim` to do the job.



### Simulation of parameter uncertainty based on a covariance step
If you have a succesful covariance step from Nonmem, `NMsim` can
sample models from the estimated variance-covariance matrix. Again,
`NMsim` does not derive confidence intervals based on the estimated
variance-covariance matrix. It samples models from it, and then you
can derive the desired confidence intervals, or whatever you need.

Again, we shall try not to get too far into details here, but remember
what we are doing here. We are assuming that the estimated
vairance-covariance matrix is a reliable estimate of the parameter
precision, implying Gaussian distribution of all parameter
uncertainties. The reason this is important to understand is that
depending on the model, this can lead to samples of parameter values
beyond some allowed range. This can lead some of the sampled models to
fail or not be meaningful. The point here is that a successful
covariance step may not be a sufficient criterion for picking this
approach to simulating uncertainty; appropriate parametrization is
another one.

Anyway, getting `NMsim` to do the work is as simple as this:

```{r,VarCov,eval=FALSE}
simlsts.VarCov <- NMsim(
    file.mod=file.mod,          ## Path to estimation input control stream
    data=dat.sim                ## simulation input data
   ,dir.sims="~/NMsim_vignette" ## where to store simulation files
   ,text.table="PRED IPRED"     ## Let Nonmem write a minimum output table
   ,method.sim=NMsim_VarCov     ## Var-Cov parameter sampling
   ,name.sim="VarCov"           ## a recognizable directory name
   ,nsims=1000                  ## sampling 500 models
   ,sge=TRUE                    ## run simulations in parallel please
)

```

You may get messages like "Unable to run job" and that the job "is not
allowed to run in any queue". Contra-intuitively to most, these
messages do not mean that the job isn't run.

We used `sge=TRUE` which means we are sending the 1000 generated jobs to the queuing system. In this case, `NMsim` does not track the execution of the jobs and does hence not collect the results once they are done. Instead it returns a small data.frame with the paths to where all the simulation output control streams will be written. You have to check the status of the jobs manually, and once they are all done, you can read all the results using `NMdata::NMscanMultiple`:

```{r,VarCov-collect,eval=FALSE}
simres.VarCov <- NMscanMultiple(
    files=simlsts.VarCov$lst
   ,merge.by.row=FALSE,quiet=T
   ,as.fun="data.table")

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_VarCov.fst"
if(run.simuls){
    write_fst(simres.VarCov,path=file.fst)
} else {
    simres.VarCov <- read_fst(file.fst,as.data.table=TRUE)
}
```

We now have simulation results from 1000 sampled models collected. We
shall do the same with the models sampled in a bootstrap, and then we
will calculate confidence intervals based on both methods.



### Simulation from a bootstrap
The other approach to simulation with parameter uncertainty currently
provided by `NMsim` is simulation from a bootstrap. Again, `NMsim`
does not run a bootstrap, it simply runs a simulation using each of
the sampled models from a bootstrap. In fact this means we don't even
need a dedicated method to achieve this, we simply run a simulation
with multiple Nonmem models as described in the begging of this
vignette. We used `PSN`'s bootstrap. We can run the simulation on all the models this way:


```{r,bootstrap-execute,eval=FALSE}
## generate a vector with paths to all the input control streams
mods.bootstrap <- list.files(path="~/NMsim_vignette_work/bs1_021_N1000/m1",
                             pattern=".+\\.mod$",full.names = T)
## number of models to be run
## length(mods.bootstrap)

simlsts.bootstrap <- NMsim(
    file.mod=mods.bootstrap   ## Estimation input control stream
   ,data=dat.sim              ## Simulation input data
   ,method.sim=NMsim_default  ## a single simulation with each sampled model
   ,dir.sims="~/NMsim_vignette/bootstrap" ## Where to save simulation results
   ,text.table="PRED IPRED"   ## Let Nonmem write a minimum output table
   ,sge=TRUE                  ## run simulations in parallel 
)

```

```{r,bootstrap-collect,eval=FALSE}
simres.bootstrap <- NMscanMultiple(files=simlsts.bootstrap$lst
                                  ,merge.by.row=FALSE
                                  ,quiet=T
                                  ,as.fun="data.table")
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_bootstrap.fst"
if(run.simuls){
    write_fst(simres.bootstrap,path=file.fst)
} else {
    simres.bootstrap <- read_fst(file.fst,as.data.table=TRUE)
}
```

`NMdata::NMscanMultiple` is a wrapper of `NMdata::NMscanData`, and just like `NMdata::NMscanData` it keeps a column by default called `model` which holds the model name, derived from the control stream file name. As an example, we can derive an estimated confidence interval of the population prediction against time by summarizing across the simulation models (samples). 


### The confidence intervals
Derivation of the confidence intervals is identical for the two methods, so we do it at once using data.table's `by` feature to separate the two methods (sampling from covariance steps and using the bootstrap samples).


```{r,uncertain-summa,eval=FALSE}
## Stacking results from the two approaches to simulating with
## parameter uncertainty.
allres <- rbind(simres.VarCov[,method:="Covariance step"],
                simres.bootstrap[,method:="Bootstrap"],
                fill=TRUE)

## long format so calculations can be done by prediction type.
allresl <- melt(allres[EVID==2],
                measure.vars=c("PRED","IPRED"),
                variable.name="pred.type",
                value.name="pred.value")

## deriving median by model and time to have a single value per model
## and time point. This is only needed in case multiple subjects are
## simulated by each model.
sum.res.model <- allresl[,
                         .(predm=median(pred.value))
                        ,by=.(method,model,TIME,pred.type)]


sum.uncertain <- sum.res.model[
   ,setNames(as.list(quantile(predm,probs=c(.025,.5,.975))),
             c("predml","predmm","predmu"))
   ,by=.(method,TIME,pred.type)]

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/sum_uncertain.fst"
if(run.simuls){
    write_fst(sum.uncertain,path=file.fst)
} else {
    sum.uncertain <- read_fst(file.fst,as.data.table=TRUE)
}
```

Plotting the two next to each other. For this simple model with a
smooth covariance step the two confidence intervals are very
similar. If you look hard, you can see minor differences.


```{r,uncertain-plots,eval=TRUE}
ggplot(sum.uncertain,aes(x=TIME,fill=pred.type))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=pred.type))+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")+
    facet_wrap(~method)

```



## Vary parameter values
Sometimes we want to simulate with some modification to the estimated model. NMsim can make such user-specified modifications to the model before simulating through the `list.sections` argument. 

The SAD study was run with a fast solution formulation. We want to see how a slower absorption rate would affect the PK prediction for the multiple dose regimen. In the model estimate, `TVKA=2.17`. We now try with a four times slower absorption:

```{r,eval=FALSE}
simres <- NMsim(file.mod=file.mod
               ,data=dat.sim
               ,dir.sims="~/NMsim_vignette" ## where to store simulation files
               ,seed=12345
                )

simres.slowabs <- NMsim(file.mod=file.mod,
                        data=dat.sim
                       ,dir.sims="~/NMsim_vignette" ## where to store simulation files
                       ,name.sim="slower_abs"
                       ,seed=12345
                       ,list.sections=list(PK=function(x)c(x,"TVKA=TVKA/4","KA=KA/4"))
                        )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_slowabs.fst"
if(run.simuls){
    write_fst(simres.slowabs,path=file.fst)
} else {
    simres.slowabs <- read_fst(file.fst,as.data.table=TRUE)
}
simres <- read_fst("simulate-results/simres.fst",as.data.table=TRUE)
```

```{r,eval=TRUE}
rbind(simres,simres.slowabs) |>
    ggplot(aes(TIME,PRED,colour=model))+
    geom_line()

```

We used `list.sections` to modify the `$PK` section. We used it to
append two lines. We could use it to modify any section in the model,
and we could essentially do any modification. However, appending to
`$PK` or `$PRED` is simple and often both robust and flexible enough.

That was a very spcific analysis of one specific `KA` value. It is often more convenient to control the numeric changes to the model using the simulation input data set rather than hard-coding numerical values into `list.sections`. The following tries a number of fold changes to `KA`.

```{r,include=TRUE,eval=FALSE}
NMdataConf(as.fun="data.table")
dat.sim.varka <- egdt(dat.sim,data.table(KASCALE=c(1,4,10)))
dat.sim.varka[,ID:=.GRP,by=.(KASCALE,ID)]
setorder(dat.sim.varka,ID,TIME,EVID)

simres.varka <- NMsim(file.mod=file.mod,
                      data=dat.sim.varka
                     ,dir.sims="~/NMsim_vignette" ## where to store simulation files
                     ,name.sim="varka"
                     ,seed=12345
                     ,list.sections=list(PK=function(x)c(x,"TVKA=TVKA/KASCALE","KA=KA/KASCALE"))
                      )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_varka.fst"
if(run.simuls){
    write_fst(simres.varka,path=file.fst)
} else {
    simres.varka <- read_fst(file.fst,as.data.table=TRUE)
}
```

```{r,eval=TRUE}
ggplot(simres.varka[simres.varka$EVID==2,],aes(TIME,PRED,colour=factor(KASCALE)))+geom_line()+labs(colour="Fold absorption prolongation")
```



<!-- ## Using NMsim to validate reimplementations of models -->

