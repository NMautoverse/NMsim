---
title: "NMsim basics"
output:
rmarkdown::html_vignette:
    toc: true
Suggests: markdown
VignetteBuilder: knitr
vignette: >
  %\VignetteIndexEntry{NMsim basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
- \usepackage{ae}
---

```{r,include = FALSE}
##knitr::opts_chunk$set(dev = "cairo_pdf")
knitr::opts_chunk$set(
                      collapse = TRUE
                     ,comment = "#>"
                     ,fig.width=7
                     ,cache=FALSE
                  )

## this changes data.table syntax. I think we can do without.
## knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

```{r,setup,include=F}
## library(devtools)
## unloadNamespace("NMsim")
## unloadNamespace("NMdata")

## load_all("~/wdirs/NMdata")
## load_all()
library(NMsim)
library(data.table)
library(NMdata)
library(dplyr)
library(tibble)
library(ggplot2)
library(patchwork)
library(tracee)
library(tidyr)

theme_set(theme_bw())
this.script <- "NMsim_basics.Rmd"
writeOutput <- TRUE
file.project <- function(...)file.path(system.file("examples",package="NMsim"),...)
found.files <- list.files(file.project("nonmem/NMsim"),pattern="noname\\.(lst|xml|ext|cov|cor|coi|phi|msf|msfi|msfo|tab)",full.names=TRUE)
unlink(found.files)
```


Built `r Sys.Date()` using NMsim `r packageVersion("NMsim")`.


## Objectives
This vignettes aims at enabling you to

* Use `NMsim` to simulate Nonmem models with a given input data set

* Distinguish between and perform the most common types of simulations: new subjects (default), typical subjects, known subjects, and simulation with parameter uncertainty

* Configure `NMsim` to use `PSN` or methods provided by `NMsim` to update Nonmem control stream initial values and to run Nonmem

* Understand pros and cons of using `PSN` vs. methods provided by `NMsim`.

<!-- * Configure `NMsim` to use `PSN`'s `update_inits` or an alternative simple method provided by `NMsim` -->

## Estimation, then simulation
The situation is like this: We collected PK and PD data on a drug
candidate. A PK model was estimated using Nonmem. We have on file
model input and output control streams (here with extensions `.mod`
and `.lst` respetively), parameter estimates (`.ext`) and estimated
random effects (`.phi`) are available.

We want predict exposure in a few dosing regimens that we are
particularly interested in. These are regimens that we have not
studied in clinical trials so far, and we have decided to use
population PK simulations for this purpose. 

The pop PK model is estimated using an ADVAN subroutine with
extravascular dosing in compartment 1 andthe central compartment is
compartment 2. 


```{r,dsCreateSim,include=FALSE}
dt.amt <- data.frame(DOSE=c(100,400))
dt.amt <- within(dt.amt,{AMT=DOSE*1000})
dt.amt
doses.sd <- NMcreateDoses(TIME=0,AMT=dt.amt)
doses.sd <- within(doses.sd,{
    dose=paste(DOSE,"mg")
    regimen="SD"
})
doses.sd


### multiple dose regimens with loading are easily created with NMcreateDoses too
## We use ADDL+II (either method easy)
dt.amt <- data.frame(AMT=c(200,100,800,400)*1000,DOSE=c(100,100,400,400))
dt.amt <- subset(dt.amt,DOSE==400)
doses.md <- NMcreateDoses(TIME=c(0,24),AMT=dt.amt,addl=data.frame(ADDL=c(0,5),II=c(0,24)))
doses.md <- within(doses.md,{
    dose=paste(DOSE,"mg")
    regimen="QD"
})
doses.md
## doses.md$ID <- max(doses.sd$ID)+doses.md$ID


## we will simulate with SD and QD
## doses.all <- bind_rows(doses.sd
##                        ,
##                        doses.md
##                        )


## Add simulation records - longer for QD regimens
dat.sim.sd <- addEVID2(doses.sd,time.sim=0:24,CMT=2)
dat.sim.md <- addEVID2(doses.md,time.sim=0:(24*7),CMT=2)

## Stack simulation data, reassign ID to be unique in combined dataset
dat.sim1 <- bind_rows(
    ##  dat.sim.sd
    ## ,
    dat.sim.md
)
dat.sim1 <- as.data.table(dat.sim1)[,ID:=.GRP,by=.(regimen,ID,DOSE)]
setorder(dat.sim1,ID,TIME,EVID)
dat.sim1$ROW <- 1:nrow(dat.sim1)

dat.sim1 <- NMorderColumns(dat.sim1)


dat.sim1 <- as_tibble(dat.sim1)
```

```{r}
NMexpandDoses(dat.sim1) %>%
    group_by(ID,regimen,DOSE,EVID,AMT) %>%
    summarize(N=length(EVID)) %>%
    spread(EVID,N)

print(as.data.table(dat.sim1),topn=5)
```

We have put together a simulation data set. We used the
`NMcreateDoses` and `addEVID2` functions from `NMsim` to do so, but
that is not the topic of this vignette. We simulate two different doses (100 mg and 400 mg) as single dose, and then the same dose levels as QD with a double loading dose.


## Simulation of new subjects
This is the first time we are using `NMsim`, and we just want to try
the simplest thing we can think of.


```{r,sim-simplest,eval=FALSE}
## file.mod <- "../nonmem/xgxr014.mod"
file.mod <- file.project("nonmem/xgxr017.mod")
file.mod <- "~/xgxg_data/nonmem/xgxr018.mod"
file.mod <- "~/xgxg_data/nonmem/xgxr021.mod"
file.mod <- file.project("nonmem/xgxr021.mod")

## unloadNamespace("NMsim")
## unloadNamespace("NMdata")
## load_all("~/wdirs//NMdata")
## load_all()

simres <- NMsim(file.mod=file.mod,
                data=dat.sim1
                ## ,method.update.inits="nmsim"
               ,dir.sims="~/NMsim_test"
               ,seed=12345
                )
```

We plot population and individual predictions as the simulations of
(in this case) the typical subject and one simulated subject. Residual
variability is not simulated in this case. More on that later in this
paper.

```{r,eval=FALSE}
as.data.table(simres) |>
    melt(measure.vars=cc(PRED,IPRED))|>
	ggplot(aes(TIME,value,colour=variable))+
    geom_line()+
    facet_wrap(~regimen+dose)

datl <- as.data.table(simres) |>
    melt(measure.vars=cc(PRED,IPRED,Y))
## datl[,type:="Prediction"]
## datl[variable=="Y",type:="Simulation"]

	ggplot(datl,aes(TIME,value,colour=variable))+
    geom_line(data=function(x)x[variable!="Y"])+
    geom_point(data=function(x)x[variable=="Y"])+
    facet_wrap(~regimen+dose)
```

<!-- That did not go well. As the error shows, `$TABLE` refers to a `ROW` column. Nonmem needs this to run the control stream as is. Since this does not happen until `$TABLE`, we have two options to fix it -->
<!-- - Add `ROW` to the input data set -->
<!-- - Modify `$TABLE` (using the `text.table`, demonstrated later) -->

Before we continue with that model, we want to compare a simulation based on this model to another model we are considering. `NMsim` can do this and collect the data into one object:

```{r,sim-twomodels,eval=FALSE}
## file.mod <- "../nonmem/xgxr014.mod"
file.mod <- file.project(c("nonmem/xgxr014.mod","nonmem/xgxr114.mod"))
simres <- NMsim(path.mod=file.mod,
                data=dat.sim1
                )
```

In case multiple models are provided, `NMsim` simply loops over them. It does collect all the results, and we can use the `model` column to separate the two simulations:

```{r,eval=FALSE}
ggplot(simres,aes(TIME,PRED,colour=model))+geom_line()+
    facet_wrap(c("regimen","dose"),scales="free")
```

For simplicity, we shall show the rest of the examples for just one model. Any of them could be run on multiple models the same way as shown above.

<!-- subproblems vs repetition of input data -->

### More subjects
To create a prediction interval based on the selected model, we need
to simulate multiple new subjects. There are two ways to easily obtain that. One is to repeat (`rbind`) the simulation input dataset, one repetetion per new subject, and then update the `ID` column to get distinct subjects. The follwing shows how one could generate 1000 subjects using `data.table`. (I use `data.table` a lot, if you can provide a good way to do this with tidyverse packages, I am happy to include that instead).

```{r,eval=FALSE}
dat.sim.1000 <- NMdata::egdt(
                            as.data.table(dat.sim1)[,!("ID")]
                           ,
                            data.table(ID=1:1000)
                        )
dat.sim.1000[,ID:=.GRP,by=.(ID,regimen,dose)]

setorder(dat.sim.1000,regimen,dose,ID,TIME,EVID)
```

We now simulate 1000 subjects by plugging in this data object:
```{r,sim-1000-data,eval=FALSE}
file.mod <- file.project("nonmem/xgxr014.mod")
simres <- NMsim(path.mod=file.mod,
                data=dat.sim.1000
                )
```

The other way to do this is making use of Nonmem's `SUBPROBLEMS` simulation feature which makes Nonmem rerun the simulation the specified number of times. Notice that to do this, we use the `dat.sim1` data without the 1000 replications. We then make use of the NMREP column generated by `NMdata::NMscanData` to redefine the `ID` column:


```{r,sim-1000-subproblem,eval=FALSE}
## file.mod <- "../nonmem/xgxr014.mod"
file.mod <- file.project("nonmem/xgxr014.mod")
simres <- NMsim(path.mod=file.mod,
                data=dat.sim1,
                subproblems=1000
                )
simres <- as.data.table(simres)[,ID:=.GRP,by=.(NMREP,ID,regimen,dose)]
```

The two approaches are computationally about equally fast, the most significant difference probably being in Nonmem reading a smaller or larger simulation input data file. It is merely a question of preference of the modeler which one to use. In a general case where the simulated patients need different dosing or sample schedules, the manual repetition of the data is needed.

We now plot a prediction interval - in this case based on the results of the simulation using `SUBPROBLEMS`; this makes no difference to how to derive the prediction interval.

```{r,eval=FALSE}
simres.pi <- simres[,setNames(as.list(quantile(IPRED,probs=c(.05,.5,.95))),cc(ll,median,ul)),
                    by=.(regimen,TIME,dose)]
simres.pi$type <- "pi"
simres.pi$pi.cover <- "90%"

p.pi.typ <- ggplot(simres.pi,aes(TIME,fill=dose))+
    geom_ribbon(aes(ymin=ll,ymax=ul,alpha=pi.cover))+
    geom_line(aes(y=median,colour=dose))+
    facet_wrap(~regimen,scales="free_x")+
    scale_alpha_manual(values=c("90%"=.5))+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")

p.pi.typ
```

## Simulation of a typical subject
A typical subject is here understood as a subject without random effects, i.e. all ETA's equal zero. It is important to realize that "typical" does not have to do with covariates which the user will still need to control in the model, in the simulation input data, or by a combination of these. Getting `NMsim` to run with all ETA's equaling zero is this easy:

```{r,eval=FALSE}
simres.typ <- NMsim(path.mod=file.mod,
                    data=dat.sim1,
                    name.sim="typSubj",
                    method.sim=NMsim_typical)

```

In the first simulation we used `PRED` from the default simulation
method to get a typical subject simulation. That will work in many
cases, but that depends on the model. The way to run a simulation with
all ETA's set to 0 is using `method.sim=NMsim_typical`.

```{r,eval=FALSE}
p.typ <- ggplot(simres.typ,aes(TIME,IPRED))+geom_line()+
    geom_line(aes(y=PRED),colour=2)
p.typ

```

## Simulation of known subjects
We sometimes want to simulate the already observed subjects. This means we want to reuse the estimated random effects (ETA's) given the subject ID's. `NMsim` has a method for this. The restriction is that all subjects (values of `ID`) in the simulation input data must have been used in the estimation input data.
```{r,eval=FALSE}
base.sim.known <- dat.sim.md[dat.sim.md$DOSE==400,]

res.mod <- NMscanData(file.mod)
ids <- data.frame(ID=unique(res.mod$ID))


dat.sim1.known <- merge(ids,
                        base.sim.known[,setdiff(colnames(base.sim.known),c("ID")),with=FALSE]
                        )
setorder(dat.sim1.known,ID,TIME,EVID)

res.known <- NMsim(file.mod,
                   data=dat.sim1.known,
                   suffix.sim="known1",
                   text.table="PRED IPRED CL V2 KA"
                  ,method.sim=NMsim_known
                   ## ,method.update.inits="nmsim"
                  ,path.nonmem="/opt/NONMEM/nm75/run/nmfe75"
                   )
```

<!-- Show a plot of the individual parameters in estimate and in sim -->

### Impute simulation times for building a PK/PD dataset
We also connected some PK data. We want to plot the PD data angainst PK. However, PD was sampled differnetly than PK, and we want to evaluate the individual predictions of the PK model at the individual PD samplng times.

Currently, there is no PD data in the example data used to build this vignette. For a PK model without time-varying covariates, the steps to to generate the data for the simulation are:

```{r,pddata,include=FALSE,eval=FALSE}
## pd <- readRDS("~/wdirs/NMsim/inst/examples/data/xgxr_pd.rds")
pd <- system.file("examples/data/xgxr_pd.rds", package = "NMsim")
```

* Take dose records from PK model estimation input data (`pkdos`). Just keep necessary columns like `ID`, `TIME`, `EVID`, `CMT`, `AMT`, `ADDL`, `II`, and any necessary covariates
* Take PD data observation records (`pdsamples`). Just keep `ID`, `TIME`, and set `EVID=2`.
* Add a unique row identifier to `pdsamples` (an integer row counter, like `ROW=1:nrow(pdsamples)`)
* Stack (`rbind` for data.tables or `bind_rows` in tidyverse) `pkdos` and `pdsamples` to one data set (`pdsim`)
* In `pdsim`, set `DV=NA`
* Sort `pdsim` at least by `ID`, `TIME` and `EVID`. There could be more depending on trial design

In case of time-varying covariates, you can keep all data records from the PK data (without `DV`), but change observation records to simulation records (`EVID=2` instead of `EVID=0`).

```{r,known-pkpd,eval=FALSE}
## Take dose records from PK model estimation input data
pkres <- NMscanData(file.mod,as.fun="data.table")
pkdos <- pkres[EVID==1,.(ID, TIME, EVID, CMT, AMT)]
## Take PD data observation records (`pdsamples`)
pd[,ROWPD:=.I]
pdsamples <- pd[EVID==0,.(ROWPD,ID,TIME,EVID=2)]
## Stack `pkdos` and `pdsamples` to one data set (`pdsim`)
pdsim <- rbind(pkdos,pdsamples,fill=TRUE)
pdsim[,DV:=NA]
## pdsim[,all(ID%in%pkres$ID)]
## pdsim[,.N,by=ID%in%pkres$ID]
pdsim <- pdsim[ID%in%pkres$ID]
setorder(pdsim,ID,TIME,EVID)
```

Then run `NMsim` like this:

```{r,known-pkpd-run,eval=FALSE}

res.pksim <- NMsim(file.mod,
                   data=pdsim,
                   suffix.sim="pkpd",
                  ,method.sim=NMsim_known
                  ,path.nonmem="/opt/NONMEM/nm75/run/nmfe75"
                  ,text.table="IPRED PRED"
                   )

```

Now rename `res.pksim$IPRED` to something meaningfull like `res.pksim$PKIPRED`, and you can merge `res.pksim` onto the PD data by the unique row identifier. 

```{r,merge-pdres,eval=FALSE}
setnames(res.pksim,"IPRED","PKIPRED")
pd2 <- mergeCheck(pd,res.pksim[,.(ROWPD,PKIPRED)],by="ROWPD",all.x=TRUE)
```

```{r,eval=FALSE}
ggplot(pd2[PKIPRED>0],aes(PKIPRED,LIDV))+
    geom_point()+
    lims(x=c(.001,.5))+
    labs(x="Individual PK prediction",y="Observed PD value") ## +
## scale_x_log10(limits=c(.001,.5))
``` 


## Simulation of parameter uncertainty
We already saw how `NMsim` can easily be used to generate new subjects
(for say prediction intervals) by using the between-subject and
between-occasion variability as described by the model. We may also
want to simulate the uncertainty of the parameter estimates (for say
confidence intervals). `NMsim` supports two different approaches to
this. 

* Simulation based on the estimated variance-covariance matrix of the
parameters as estimated by a successful `$COVARIANCE` step in Nonmem.

* Simulation based on a bootstrap of the model. `NMsim` does not
provide functions to run the bootstrap, but it can use the results
of sampled models, like what is generated by `PSN`'s bootstrap
function.

It is beyond the scope of this vignette to describe the pros and cons
of those two approaches. The following examples serve to exlain the
preequisites for using `NMsim` to do it, and obviously how to get
`NMsim` to do the job.



### Simulation of parameter uncertainty based on a covariance step
If you have a succesful covariance step from Nonmem, `NMsim` can
sample models from the estimated variance-covariance matrix. Again,
`NMsim` does not derive confidence intervals based on the estimated
variance-covariance matrix. It samples models from it, and then you
can derive the desired confidence intervals, or whatever you need.

Again, we shall try not to get too far into details here, but remember
what we are doing here. We are assuming that the estimated
vairance-covariance matrix is a reliable estimate of the parameter
precision, implying Gaussian distribution of all parameter
uncertainties. The reason this is important to understand is that
depending on the model, this can lead to samples of parameter values
beyond some allowed range. This can lead some of the sampled models to
fail or not be meaningful. The point here is that a successful
covariance step may not be a sufficient criterion for picking this
approach to simulating uncertainty; appropriate parametrization is
another one.

Anyway, getting `NMsim` to do the work is as simple as this:

```{r,VarCov,eval=FALSE}
## file.mod.cov <- file.project("nonmem/xgxr114.mod")
NMdataConf(path.nonmem="/opt/NONMEM/nm75/run/nmfe75")

file.mod.cov <- "~/xgxg_data/nonmem/xgxr017.mod"
NMsim(
    path.mod=file.mod.cov,
    data=dat.sim1
   ,dir.sims="simulations"
   ,method.sim=NMsim_VarCov ## Var-Cov parameter sampling
   ,name.sim="VarCov"       ## a recognizable directory name
   ,nsims=500               ## sampling 500 models
    ## ,method.execute="psn"    ## use PSN's execute to allow for parallel execution
   ,method.execute="directory"    ## 
   ,sge=TRUE                ## run simulations in parallel please
)
```
We used `sge=TRUE` which means we are sending the 500 generated jobs to the queuing system. In this case, `NMsim` does not track the execution of the jobs and does hence not collect the results once they are done. You have to check the status of the jobs manually, and once they are all done, you can read all the results using `NMdata::NMscanMultiple`:

```{r,VarCov-collect,eval=FALSE}
simres.VarCov <- NMscanMultiple(## dir="simulations/xgxr114_VarCov"
    dir=file.path("simulations",paste0(basename(fnExtension(file.mod.cov,"")),"_VarCov"))
   ,file.pattern=".+\\.lst$"
   ,merge.by.row=FALSE,quiet=T
   ,as.fun="data.table")

```

`NMdata::NMscanMultiple` is a wrapper of `NMdata::NMscanData`, and just like `NMdata::NMscanData` it keeps a column by default called `model` which holds the model name, derived from the control stream file name. As an example, we can derive an estimated confidence interval of the population prediction against time by summarizing across the simulation models (samples):

```{r,VarCov-summarize,eval=FALSE}

allresl <- melt(simres.VarCov[EVID==2],measure.vars=cc(PRED,IPRED),variable.name="pred.type",value.name="pred")

sum.res.model <- allresl[,
                         .(predm=quantile(pred,probs=c(.5)))
                        ,by=.(model,regimen,dose,DOSE,TIME,pred.type)]


sum.res <- sum.res.model[,
                         setNames(as.list(quantile(predm,probs=c(.025,.5,.975))),cc(predml,predmm,predmu))

                        ,by=.(regimen,dose,DOSE,TIME,pred.type)]




ggplot(sum.res,aes(x=TIME,fill=dose))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=dose))+
    ## facet_grid(regimen~pred.type,scales="free_x")
    facet_wrap(cc(regimen,pred.type),scales="free_x")

## 400 mg only
p.cipi.VarCov <- ggplot(sum.res[DOSE==400],aes(x=TIME,fill=pred.type))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=pred.type))+
    facet_wrap("regimen",scales="free_x")+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")



```

### Simulation from a bootstrap
The other approach to simulation with parameter uncertainty currently
provided by `NMsim` is simulation from a bootstrap. Again, `NMsim`
does not run a bootstrap, it simply runs a simulation using each of
the sampled models from a bootstrap. In fact this means we don't even
need a dedicated method to achieve this, we simply run a simulation
with multiple Nonmem models as described in the begging of this
vignette. We used `PSN`'s bootstrap. We can run the simulation on all the models this way:


```{r,bootstrap-execute,eval=FALSE}
## generate a vector with paths to all the input control streams

## mods.bootstrap <- list.files(path="../nonmem/bs1_014_N1000/m1",pattern=".+\\.mod$",full.names = T)
mods.bootstrap <- list.files(path="~/xgxg_data/nonmem/bootstrap_dir2/m1/",pattern=".+\\.mod$",full.names = T)

NMsim(
    path.mod=mods.bootstrap,
    data=dat.sim1
   ,method.sim=NMsim_default ## a single simulation with each sampled model
   ,dir.sims="simulations/bootstrap"
    ## ,name.sim="bootstrap"       ## a recognizable directory name
   ,method.execute="psn"    ## use PSN's execute to allow for parallel execution
   ,text.table="PRED IPRED"
   ,sge=TRUE                ## run simulations in parallel please
)
```

Reading and post-processing the results is similar to the same steps
above when we used the covariance step.

```{r,bootstrap-collect,eval=FALSE}
## ~/xgxg_data/nonmem/bootstrap_dir2/m1/NMsim/bs_pr1_100_bootstrap/NMsim_bs_pr1_100_bootstrap.mod
files.lst <- list.files("simulations/bootstrap",recursive=TRUE,pattern=".lst$",full.names=TRUE)

simres.bootstrap <- NMscanMultiple(files=files.lst
                                   ## dir="
                                   ## ,file.pattern=".+\\.lst$"
                                  ,merge.by.row=FALSE,quiet=T
                                  ,as.fun="data.table")

allresl <- melt(simres.bootstrap[EVID==2],measure.vars=cc(PRED,IPRED),variable.name="pred.type",value.name="pred")

sum.res.model <- allresl[,
                         .(predm=quantile(pred,probs=c(.5)))
                        ,by=.(model,regimen,dose,DOSE,TIME,pred.type)]


sum.res.bootstrap <- sum.res.model[,
                                   setNames(as.list(quantile(predm,probs=c(.025,.5,.975))),cc(predml,predmm,predmu))

                                  ,by=.(regimen,dose,DOSE,TIME,pred.type)]


```

```{r,bootstrap-summarize,eval=FALSE}

p.cipi.bootstrap <- ggplot(sum.res.bootstrap[DOSE==400],aes(x=TIME,fill=pred.type))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=pred.type))+
    facet_wrap("regimen",scales="free_x")+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")

p.cipi.bootstrap

```

```{r,compare-plots,eval=FALSE}

p.cipi.VarCov+
    lims(y=c(0,12500))+
    labs(subtitle="Covariance step")+
    p.cipi.bootstrap+
    lims(y=c(0,12500))+
    labs(subtitle="Bootstrap")
```

## Add residual variability
`NMsim` currently does not provide any way to add simulation of
residual variability with Nonmem. It does however provide a method to
simulate residual variability in R, based on the Nonmem parameter
estimates. The function is called `addResVar()` and supports additive,
proportional, and combined (additive and proportional) error
models. It can also add the residual error on log scale (exponential
error model).

`NMresVar` supports both estimation using `$SIGMA` and `$THETA` (in Nonmem). The user has to specify which of the two methods were used in the Nonmem model using the `par.type` argument. The other thing that must be specified is the parameter numbers for the standard deviations or variances. The model simulated in this vignette has this combined error model estimated using the `$SIGMA` matrix:

```
  Y=F+F*ERR(1)+ERR(2)
```

We now specify for `addResVar` to find the variance for the proportional component in `$SIGMA[1,1]` and the one for the additive component in `$SIGMA[2,2]`. In this case where `SIGMA` is used, the off-diagonal (covariance) elements of the `$SIGMA` matrix are also used for the simulation. 

```{r,eval=FALSE}
simres.with.resvar <- addResVar(simres,path.ext=fnExtension(file.mod,"ext"),par.type="SIGMA",prop=1,add=2)
```

## Vary parameter values
```{r,include=FALSE,eval=FALSE}
dt.inp2 <- rbind(
    transform(dt.inp,CLSCALE=1,sim="CL unchanged")
    ,transform(dt.inp,CLSCALE=2,sim="Double CL")
)
dt.inp2[,ID:=.GRP,by=.(sim,ID)]
NMcheckData(dt.inp2)


simres2 <- NMsim(path.mod=path.model,dt.inp2,name.sim="20mg_CL2"
                ,list.sections=list(PK=function(x)c(x,"CLP=CLP*CLSCALE","CLM=CLM*CLSCALE")))

ggplot(simres2[EVID==2],aes(TIME,PRED,colour=sim))+geom_line()+facet_wrap(~compound)


## Configuration of how to execute Nonmem
`NMsim` supports two ways

## Other important arguments to `NMsim`

<!-- simres.typ$type <- "typical" -->
