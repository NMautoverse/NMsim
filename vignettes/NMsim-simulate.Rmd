---
title: "NMsim Simulation Methods"
output:
rmarkdown::html_vignette:
    toc: true
Suggests: markdown
VignetteBuilder: knitr
vignette: >
  %\VignetteIndexEntry{Simulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
- \usepackage{ae}
---

```{r,include = FALSE}
##knitr::opts_chunk$set(dev = "cairo_pdf")
knitr::opts_chunk$set(
                      collapse = TRUE
                     ,comment = "#>"
                     ,fig.width=7
                     ,cache=FALSE
                  )

## this changes data.table syntax. I think we can do without.
## knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

```{r,setup,include=F}
## library(devtools)
## unloadNamespace("NMsim")
## unloadNamespace("NMdata")

## load_all("~/wdirs/NMdata")
## load_all()
library(NMsim)
library(data.table)
library(NMdata)
library(dplyr)
library(tibble)
library(ggplot2)
library(patchwork)
library(tracee)
library(tidyr)
library(fst)
library(knitr)
## NMdataConf(path.nonmem="/opt/NONMEM/nm75/run/nmfe75")
## NMdataConf(dir.psn=NULL)

theme_set(theme_bw())
this.script <- "NMsim-simulate.Rmd"
writeOutput <- TRUE
file.project <- function(...)file.path(system.file("examples",package="NMsim"),...)
## file.project <- function(...)file.path("../inst/examples",...)
## file.project <- function(...)file.path("~/wdirs/NMsim/inst/examples",...)

found.files <- list.files(file.project("nonmem/NMsim"),pattern="noname\\.(lst|xml|ext|cov|cor|coi|phi|msf|msfi|msfo|tab)",full.names=TRUE)
unlink(found.files)

run.simuls <- FALSE
NMdataConf(as.fun="data.table")
```


Built `r Sys.Date()` using NMsim `r packageVersion("NMsim")`.


## Objectives
This vignettes aims at enabling you to

* Use `NMsim` to simulate Nonmem models with a given input data set

* Distinguish between and perform the most common types of simulations: 
- new subjects (default), 
- typical subjects, 
- known (estimated) subjects, 
- simulation with parameter uncertainty

* Simulation with parameters modified from the estimated values

## Prerequisites
You should have configured `NMsim` with the path to the Nonmem
installation and maybe also PSN. See
[`NMsim-config.html`](https://philipdelff.github.io/NMsim/articles/NMsim-config.html). Don't
worry - it is very easy.


## Estimation, then simulation
The situation is like this: We collected PK and PD data from a single ascending dose 
trial on a drug candidate. 

```{r,include=TRUE,echo=FALSE}
file.mod <- file.project("nonmem/xgxr021.mod")
res <- NMscanInput(file.mod,quiet=TRUE)
ggplot(res,aes(TIME,DV))+
    geom_point()+
    facet_wrap(~trtact)

```

A PK model was estimated using Nonmem. We have on file
model input and output control streams (here with extensions `.mod`
and `.lst` respetively), parameter estimates (`.ext`) and estimated
random effects (`.phi`) are available.

We want to predict exposure in a multiple dose regimen that we are
particularly interested in. This is a regimen that we have not
studied in clinical trials so far, and we have decided to use
population PK simulations for this purpose. 

The pop PK model was estimated using an ADVAN subroutine with
extravascular dosing in compartment 1 and the central compartment is
compartment 2.

It does not matter to NMsim how we create a simulation data set as
long as we get it into a data.frame structure. We used functions
included with NMsim for the purpose, but you can use anything. We
create a regimen with a loading dose of 300 mg followed by 150 QD for
6 days. Notice that the compartment numbers match the compartment
numbers that were used when estimating the model.

```{r,dsCreateSim,include=TRUE}
### multiple dose regimens with loading are easily created with NMcreateDoses too
## We use ADDL+II (either method easy)
doses <- NMcreateDoses(TIME=c(0,24),AMT=c(300,150),addl=data.frame(ADDL=c(0,5),II=c(0,24)),CMT=1)
doses <- transform(doses,trt="300 mg then 150 mg QD")

## Add simulation records - longer for QD regimens
dat.sim <- addEVID2(doses,time.sim=0:(24*7),CMT=2)

## sort data set 
setorder(dat.sim,ID,TIME,EVID)

```

We check the simulation data set for various potential issues in
Nonmem data sets using `NMdata::NMcheckData` and summarize the number
of doses and observations:

```{r}
NMcheckData(dat.sim,type.data="sim")
```
```{r,echo=TRUE}
NMexpandDoses(dat.sim)[,.(Nrows=.N),keyby=.(trt,EVID,AMT)] |>
    kable()
```

Showing the top five rows for understanding what the data now looks like. Notice that the following are _not_ issues:

- Data contains a mix of numeric and non-numeric columns
- Columns are not sorted in Nonmem-friendly style with non-numeric columns to the right


```{r}
dat.sim[1:5,]
```

## Simulation of a new subject
This is the first time we are using `NMsim`, and we just want to try
the simplest thing we can think of. Simulate a new subject on the
considerd multiple dose regimen with our estimated PK model from the
single dose study.


```{r,sim-simplest,eval=FALSE}
file.mod <- file.project("nonmem/xgxr021.mod")

simres <- NMsim(file.mod=file.mod,
                data=dat.sim)
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres.fst"
if(run.simuls){
    write_fst(simres,path=file.fst)
} else {
    simres <- read_fst(file.fst)
}
```

We plot population and individual predictions as the simulations of
(in this case) the typical subject and one simulated subject. Residual
variability is not simulated in this case. More on that later in this
paper.

```{r,eval=TRUE}
datl <- as.data.table(simres) |>
    melt(measure.vars=cc(PRED,IPRED,Y))
## datl[,type:="Prediction"]
## datl[variable=="Y",type:="Simulation"]

ggplot(datl,aes(TIME,value,colour=variable))+
    geom_line(data=function(x)x[variable!="Y"])+
    geom_point(data=function(x)x[variable=="Y"])+
    facet_wrap(~trt)
```

The reason we can plot a simulation with residual variability is that the control stream includes a variable `Y` defined with residual variability in `$ERROR`:
```
  Y=F+F*ERR(1)+ERR(2)
```

## Multiple models
Before we continue with that model, we want to compare a simulation based on this model to another model we are considering. `NMsim` can do this and collect the data into one object:

```{r,sim-twomodels,eval=FALSE}
## file.mod <- "../nonmem/xgxr014.mod"
files.2.mod <- file.project(c("nonmem/xgxr021.mod","nonmem/xgxr114.mod"))
simres.2models <- NMsim(file.mod=files.2.mod,
                        data=dat.sim
                        )
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_2models.fst"
if(run.simuls){
    write_fst(simres.2models,path=file.fst)
} else {
    simres.2models <- read_fst(file.fst)
}
```


In case multiple models are provided, `NMsim` simply loops over them. It does collect all the results, and we can use the `model` column to separate the two simulations:

```{r,eval=TRUE}
ggplot(simres.2models,aes(TIME,PRED,colour=model))+geom_line()+
    facet_wrap(c("trt"),scales="free")
```

For simplicity, we shall show the rest of the examples for just one model. Any of them could be run on multiple models the same way as shown above.

<!-- subproblems vs repetition of input data -->

## More subjects and prediction intervals
To create a prediction interval based on the selected model, we need
to simulate multiple new subjects. There are two ways to easily obtain
that. One is to repeat (`rbind`) the simulation input dataset, one
repetetion per new subject, and then update the `ID` column to get
distinct subjects. 

### Multiple subjects created in simulation input data
The follwing shows how one could generate 1000
subjects using `data.table`. (I use `data.table` a lot, if you can
provide a good way to do this without, I am happy to
include that).

```{r,eval=FALSE}
dat.sim.1000 <- NMdata::egdt(
                            as.data.table(dat.sim)[,!("ID")]
                           ,
                            data.table(ID=1:1000)
                        )
dat.sim.1000[,ID:=.GRP,by=.(ID,trt)]
## order with respect to new IDs
setorder(dat.sim.1000,trt,ID,TIME,EVID)
## check dataset
NMcheckData(dat.sim.1000,type.data="sim")
```

We now simulate 1000 subjects by plugging in this data object:
```{r,sim-1000-data,eval=FALSE}
simres.n1000.1 <- NMsim(file.mod=file.mod,
                        data=dat.sim.1000
                        )
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_n1000_1.fst"
if(run.simuls){
    write_fst(simres.n1000.1,path=file.fst)
} else {
    simres.n1000.1 <- read_fst(file.fst)
}
```

### Multiple subjects generated by Nonmem
The other way to simulate multiple subjects is making use of Nonmem's `SUBPROBLEMS` simulation feature which makes Nonmem rerun the simulation the specified number of times. Notice that to do this, we use the `dat.sim` data without the 1000 replications. We then make use of the NMREP column generated by `NMdata::NMscanData` to redefine the `ID` column:


```{r,sim-1000-subproblem,eval=FALSE}
## file.mod <- "../nonmem/xgxr014.mod"
## file.mod <- file.project("nonmem/xgxr014.mod")
simres.n1000.2 <- NMsim(file.mod=file.mod,
                        data=dat.sim,
                        subproblems=1000
                        )
simres.n1000.2 <- as.data.table(simres.n1000.2)[,ID:=.GRP,by=.(NMREP,ID,trt)]
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_n1000_2.fst"
if(run.simuls){
    write_fst(simres.n1000.2,path=file.fst)
} else {
    simres.n1000.2 <- read_fst(file.fst)
}
```


The two approaches are computationally about equally fast, the most significant difference probably being in Nonmem reading a smaller or larger simulation input data file. Unless the input dataset becomes very large, it is merely a question of preference of the modeler which one to use. In a case where the simulated patients need different dosing or sample schedules, the manual construction of the data is needed - because it's not a straightforward replication.

### Generate the prediction interval
We now plot a prediction interval - in this case based on the results of the simulation using `SUBPROBLEMS`; this makes no difference to how to derive the prediction interval.

```{r,eval=TRUE}
simres.pi <- as.data.table(simres.n1000.2)[,setNames(as.list(quantile(IPRED,probs=c(.05,.5,.95))),cc(ll,median,ul)),
                                           by=.(trt,TIME)]
simres.pi$type <- "pi"
simres.pi$pi.cover <- "90%"

p.pi.typ <- ggplot(simres.pi,aes(TIME,fill=trt))+
    geom_ribbon(aes(ymin=ll,ymax=ul,alpha=pi.cover))+
    geom_line(aes(y=median,colour=trt))+
    ## facet_wrap(~trt,scales="free_x")+
    scale_alpha_manual(values=c("90%"=.5))+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")

p.pi.typ
```

## Simulation of a typical subject
A typical subject is here understood as a subject without random effects, i.e. all ETA's equal zero. It is important to realize that "typical" does not have to do with covariates which the user will still need to control in the model, in the simulation input data, or by a combination of these. Getting `NMsim` to run with all ETA's equaling zero is this easy:

```{r,eval=FALSE}
simres.typ <- NMsim(file.mod=file.mod,
                    data=dat.sim,
                    name.sim="typSubj",
                    method.sim=NMsim_typical)

```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_typ.fst"
if(run.simuls){
    write_fst(simres.typ,path=file.fst)
} else {
    simres.typ <- read_fst(file.fst)
}
```


In the first simulation we used `PRED` from the default simulation
method to get a typical subject simulation. That will work in many
cases, but that depends on the model. The way to run a simulation with
all ETA's set to 0 is using `method.sim=NMsim_typical`.

```{r,eval=TRUE}
p.typ <- ggplot(simres.typ,aes(TIME,IPRED,color=trt))+geom_line()+
    geom_line(aes(y=PRED))
p.typ

```

## Simulation of known subjects
We sometimes want to simulate the already observed subjects. This means we want to reuse the estimated random effects (ETA's) given the subject ID's. `NMsim` has a method for this. The restriction is that all subjects (values of `ID`) in the simulation input data must have been used in the estimation input data.

```{r,eval=FALSE}
## read model results just to extract the observed ID's
res.mod <- NMscanData(file.mod,quiet=TRUE)
ids <- data.frame(ID=unique(res.mod$ID))

## Repeat the simulation data set for each ID and order accordingly
dat.sim.known <- merge(ids,
                       dat.sim[,setdiff(colnames(base.sim.known),c("ID")),with=FALSE]
                       )
setorder(dat.sim.known,ID,TIME,EVID)
## check data
NMcheckData(dat.sim.known,type.data="sim")

simres.known <- NMsim(file.mod=file.mod,
                      data=dat.sim.known,
                      name.sim="known1",
                      text.table="PRED IPRED CL V2 KA"
                     ,method.sim=NMsim_known
                      )
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_known.fst"
if(run.simuls){
    write_fst(simres.known,path=file.fst)
} else {
    simres.known <- read_fst(file.fst)
}
```

And the simulation results are plotted for each subject.
```{r,eval=TRUE}
ggplot(as.data.table(simres.known)[EVID==2],aes(TIME,IPRED,colour=factor(ID)))+
    geom_line()+
    theme(legend.position="none")
```

<!-- Show a plot of the individual parameters in estimate and in sim -->

### Impute simulation times for building a PK/PD dataset
We also connected some PK data. We want to plot the PD data angainst
PK. However, PD was sampled differnetly than PK, and we want to
evaluate the individual predictions of the PK model at the individual
PD samplng times.

Currently, there is no PD data in the example data used to build this
vignette. For a PK model without time-varying covariates, the steps to
to generate the data for the simulation are:

```{r,pddata,include=FALSE,eval=TRUE}
## pd <- readRDS("~/wdirs/NMsim/inst/examples/data/xgxr_pd.rds")
## pd <- system.file("examples/data/xgxr_pd.rds", package = "NMsim")
pd <- readRDS(file.project("data/xgxr_pd.rds")) |> as.data.table()
```

* Take dose records from PK model estimation input data (`pkdos`). Just keep necessary columns like `ID`, `TIME`, `EVID`, `CMT`, `AMT`, `ADDL`, `II`, and any necessary covariates
* Take PD data observation records (`pdsamples`). Just keep `ID`, `TIME`, and set `EVID=2`.
* Add a unique row identifier to `pdsamples` (an integer row counter, like `ROW=1:nrow(pdsamples)`)
* Stack (`rbind` for data.tables or `bind_rows` in tidyverse) `pkdos` and `pdsamples` to one data set (`pdsim`)
* In `pdsim`, set `DV=NA`
* Sort `pdsim` at least by `ID`, `TIME` and `EVID`. There could be more depending on trial design

In case of time-varying covariates, you can keep all data records from the PK data (without `DV`), but change observation records to simulation records (`EVID=2` instead of `EVID=0`).

```{r,known-pkpd,eval=TRUE}
## Take dose records from PK model estimation input data
pkres <- NMscanData(file.mod,quiet=TRUE)
pkdos <- pkres[EVID==1,.(ID, TIME, EVID, CMT, AMT)]
## Take PD data observation records (`pdsamples`)
pd[,ROWPD:=.I]
pdsamples <- pd[EVID==0,.(ROWPD,ID,TIME,EVID=2)]
## Stack `pkdos` and `pdsamples` to one data set (`pdsim`)
pdsim <- rbind(pkdos,pdsamples,fill=TRUE)
pdsim[,DV:=NA]
pdsim <- pdsim[ID%in%pkres$ID]
setorder(pdsim,ID,TIME,EVID)
```

Then run `NMsim` like this:

```{r,known-pkpd-run,eval=FALSE}

simres.pksim <- NMsim(file.mod,
                      data=pdsim,
                      name.sim="pkpd",
                     ,method.sim=NMsim_known
                     ,path.nonmem="/opt/NONMEM/nm75/run/nmfe75"
                     ,text.table="IPRED PRED"
                      )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_pksim.fst"
if(run.simuls){
    write_fst(simres.pksim,path=file.fst)
} else {
    simres.pksim <- read_fst(file.fst)
}
```


Now rename `res.pksim$IPRED` to something meaningfull like `res.pksim$PKIPRED`, and you can merge `res.pksim` onto the PD data by the unique row identifier. 

```{r,merge-pdres,eval=TRUE}
setnames(simres.pksim,"IPRED","PKIPRED")
setDT(simres.pksim)
pd2 <- mergeCheck(pd,simres.pksim[,.(ROWPD,PKIPRED)],by="ROWPD",all.x=TRUE)
```

```{r,eval=TRUE}
ggplot(pd2[!is.na(LIDV)&!is.na(PKIPRED)],aes(PKIPRED,LIDV))+
    geom_point()+
    ##    lims(x=c(.001,.5))+
    labs(x="Individual PK prediction",y="Observed PD value") ## +
``` 


## Simulation of parameter uncertainty
We already saw how `NMsim` can easily be used to generate new subjects
(for say prediction intervals) by using the between-subject and
between-occasion variability as described by the model. We may also
want to simulate the uncertainty of the parameter estimates (for say
confidence intervals). `NMsim` supports two different approaches to
this. 

* Simulation based on the estimated variance-covariance matrix of the
parameters as estimated by a successful `$COVARIANCE` step in Nonmem.

* Simulation based on a bootstrap of the model. `NMsim` does not
provide functions to run the bootstrap, but it can use the results
of sampled models, like what is generated by `PSN`'s bootstrap
function.

It is beyond the scope of this vignette to describe the pros and cons
of those two approaches. The following examples serve to exlain the
preequisites for using `NMsim` to do it, and obviously how to get
`NMsim` to do the job.



### Simulation of parameter uncertainty based on a covariance step
If you have a succesful covariance step from Nonmem, `NMsim` can
sample models from the estimated variance-covariance matrix. Again,
`NMsim` does not derive confidence intervals based on the estimated
variance-covariance matrix. It samples models from it, and then you
can derive the desired confidence intervals, or whatever you need.

Again, we shall try not to get too far into details here, but remember
what we are doing here. We are assuming that the estimated
vairance-covariance matrix is a reliable estimate of the parameter
precision, implying Gaussian distribution of all parameter
uncertainties. The reason this is important to understand is that
depending on the model, this can lead to samples of parameter values
beyond some allowed range. This can lead some of the sampled models to
fail or not be meaningful. The point here is that a successful
covariance step may not be a sufficient criterion for picking this
approach to simulating uncertainty; appropriate parametrization is
another one.

Anyway, getting `NMsim` to do the work is as simple as this:

```{r,VarCov,eval=FALSE}
simlsts.VarCov <- NMsim(
    file.mod=file.mod,
    data=dat.sim
   ,dir.sims="~/NMsim_vignette"
   ,method.sim=NMsim_VarCov ## Var-Cov parameter sampling
   ,name.sim="VarCov"       ## a recognizable directory name
   ,nsims=1000               ## sampling 500 models
   ,sge=TRUE                ## run simulations in parallel please
)

```

You may get messages like "Unable to run job" and that the job "is not
allowed to run in any queue". Contra-intuitively to most, these
messages do not mean that the job isn't run.

We used `sge=TRUE` which means we are sending the 500 generated jobs to the queuing system. In this case, `NMsim` does not track the execution of the jobs and does hence not collect the results once they are done. You have to check the status of the jobs manually, and once they are all done, you can read all the results using `NMdata::NMscanMultiple`:

```{r,VarCov-collect,eval=FALSE}
simres.VarCov <- NMscanMultiple(
    files=simlsts.VarCov$lst
   ,merge.by.row=FALSE,quiet=T
   ,as.fun="data.table")

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_VarCov.fst"
if(run.simuls){
    write_fst(simres.VarCov,path=file.fst)
} else {
    simres.VarCov <- read_fst(file.fst)
}
```


`NMdata::NMscanMultiple` is a wrapper of `NMdata::NMscanData`, and just like `NMdata::NMscanData` it keeps a column by default called `model` which holds the model name, derived from the control stream file name. As an example, we can derive an estimated confidence interval of the population prediction against time by summarizing across the simulation models (samples):

```{r,VarCov-summarize,eval=FALSE}
setDT(simres.VarCov)
allresl <- melt(simres.VarCov[EVID==2],measure.vars=cc(PRED,IPRED),variable.name="pred.type",value.name="pred")

sum.res.VarCov <- allresl[,
                          .(predm=quantile(pred,probs=c(.5)))
                         ,by=.(model,trt,TIME,pred.type)]


sum.VarCov <- sum.res.VarCov[,
                             setNames(as.list(quantile(predm,probs=c(.025,.5,.975))),cc(predml,predmm,predmu))

                            ,by=.(trt,TIME,pred.type)]

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/sum_VarCov.fst"
if(run.simuls){
    write_fst(sum.VarCov,path=file.fst)
} else {
    sum.VarCov <- read_fst(file.fst)
}
```



```{r}

p.cipi.VarCov <- ggplot(sum.VarCov,aes(x=TIME,fill=pred.type))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=pred.type))+
    facet_wrap("trt",scales="free_x")+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")

```


### Simulation from a bootstrap
The other approach to simulation with parameter uncertainty currently
provided by `NMsim` is simulation from a bootstrap. Again, `NMsim`
does not run a bootstrap, it simply runs a simulation using each of
the sampled models from a bootstrap. In fact this means we don't even
need a dedicated method to achieve this, we simply run a simulation
with multiple Nonmem models as described in the begging of this
vignette. We used `PSN`'s bootstrap. We can run the simulation on all the models this way:


```{r,bootstrap-execute,eval=FALSE}
## generate a vector with paths to all the input control streams
mods.bootstrap <- list.files(path="~/NMsim_vignette_work/bs1_021_N1000/m1",pattern=".+\\.mod$",full.names = T)
## number of models to be run
## length(mods.bootstrap)

simlsts.bootstrap <- NMsim(
    file.mod=mods.bootstrap
   ,data=dat.sim
   ,method.sim=NMsim_default ## a single simulation with each sampled model
   ,dir.sims="~/NMsim_vignette/bootstrap"
   ,text.table="PRED IPRED"
   ,sge=TRUE                ## run simulations in parallel 
)

```
Reading and post-processing the results is similar to the same steps
above when we used the covariance step.

```{r,bootstrap-collect,eval=FALSE}
simres.bootstrap <- NMscanMultiple(files=simlsts.bootstrap$lst
                                  ,merge.by.row=FALSE
                                  ,quiet=T
                                  ,as.fun="data.table")
simres.bootstrap[,.(Nmodels=uniqueN(model),Nrows=.N)]
```

```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_bootstrap.fst"
if(run.simuls){
    write_fst(simres.bootstrap,path=file.fst)
} else {
    simres.bootstrap <- read_fst(file.fst,as.data.table=TRUE)
}
```



```{r,bootstrap-summa,eval=FALSE}
allresl <- melt(simres.bootstrap[EVID==2],measure.vars=cc(PRED,IPRED),variable.name="pred.type",value.name="pred")

sum.res.model <- allresl[,
                         .(predm=quantile(pred,probs=c(.5)))
                        ,by=.(model,TIME,pred.type)]


sum.bootstrap <- sum.res.model[,
                               setNames(as.list(quantile(predm,probs=c(.025,.5,.975))),cc(predml,predmm,predmu))

                              ,by=.(TIME,pred.type)]

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/sum_bootstrap.fst"
if(run.simuls){
    write_fst(sum.bootstrap,path=file.fst)
} else {
    sum.bootstrap <- read_fst(file.fst)
}
```


```{r,bootstrap-plot,eval=TRUE}

p.cipi.bootstrap <- ggplot(sum.bootstrap,aes(x=TIME,fill=pred.type))+
    geom_ribbon(aes(ymin=predml,ymax=predmu),alpha=.5)+
    geom_line(aes(y=predmm,colour=pred.type))+
    ## facet_wrap("regimen",scales="free_x")+
    labs(x="Hours since first dose",y="Concentration (ng/mL)")

## p.cipi.bootstrap

```

```{r,compare-plots,eval=TRUE}
ymax <- 6
p.cipi.VarCov+
    lims(y=c(0,ymax))+
    labs(subtitle="Covariance step")+
    p.cipi.bootstrap +
    lims(y=c(0,ymax))+
    labs(subtitle="Bootstrap")+
    plot_layout(guides="collect") & theme(legend.position="bottom")
```

## Add residual variability
`NMsim` currently does not provide any way to add simulation of
residual variability with Nonmem. It does however provide a method to
simulate residual variability in R, based on the Nonmem parameter
estimates. The function is called `addResVar()` and supports additive,
proportional, and combined (additive and proportional) error
models. It can also add the residual error on log scale (exponential
error model).

`NMresVar` supports both estimation using `$SIGMA` and `$THETA` (in Nonmem). The user has to specify which of the two methods were used in the Nonmem model using the `par.type` argument. The other thing that must be specified is the parameter numbers for the standard deviations or variances. The model simulated in this vignette has this combined error model estimated using the `$SIGMA` matrix:

```
  Y=F+F*ERR(1)+ERR(2)
```

We now specify for `addResVar` to find the variance for the proportional component in `$SIGMA[1,1]` and the one for the additive component in `$SIGMA[2,2]`. In this case where `SIGMA` is used, the off-diagonal (covariance) elements of the `$SIGMA` matrix are also used for the simulation. 

```{r,eval=FALSE}
simres.with.resvar <- addResVar(simres,path.ext=fnExtension(file.mod,"ext"),par.type="SIGMA",prop=1,add=2)
```

## Vary parameter values
Sometimes we want to simulate with some modification to the estimated model. NMsim can make such user-specified modifications to the model before simulating through the `list.sections` argument. 

The SAD study was run with a fast solution formulation. We want to see how a slower absorption rate would affect the PK prediction for the multiple dose regimen. In the model estimate, `TVKA=2.17`. We now try with a four times slower absorption:

```{r,eval=FALSE}
simres.slowabs <- NMsim(file.mod=file.mod,
                        data=dat.sim
                       ,dir.sims="~/NMsim_test"
                       ,name.sim="slower_abs"
                       ,seed=12345
                       ,list.sections=list(PK=function(x)c(x,"TVKA=TVKA/4","KA=KA/4"))
                        )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_slowabs.fst"
if(run.simuls){
    write_fst(simres.slowabs,path=file.fst)
} else {
    simres.slowabs <- read_fst(file.fst)
}
```

```{r,eval=TRUE}
simres.slowabs |> findCovs()

rbind(simres,simres.slowabs) |>
    ggplot(aes(TIME,PRED,colour=model))+
    geom_line()

```

We used `list.sections` to modify the `$PK` section. We used it to
append two lines. We could use it to modify any section in the model,
and we could essentially do any modification. However, appending to
`$PK` or `$PRED` is simple and often both robust and flexible enough.

That was a very spcific analysis of one specific `KA` value. It is often more convenient to control the numeric changes to the model using the simulation input data set rather than hard-coding numerical values into `list.sections`. The following tries a number of fold changes to `KA`.

```{r,include=TRUE,eval=FALSE}
NMdataConf(as.fun="data.table")
dat.sim.varka <- egdt(dat.sim,data.table(KASCALE=c(1,4,10)))
dat.sim.varka[,ID:=.GRP,by=.(KASCALE,ID)]
setorder(dat.sim.varka,ID,TIME,EVID)

simres.varka <- NMsim(file.mod=file.mod,
                      data=dat.sim.varka
                     ,dir.sims="~/NMsim_test"
                     ,name.sim="varka"
                     ,seed=12345
                     ,list.sections=list(PK=function(x)c(x,"TVKA=TVKA/KASCALE","KA=KA/KASCALE"))
                      )

```
```{r,include=FALSE,eval=TRUE}
file.fst <- "simulate-results/simres_varka.fst"
if(run.simuls){
    write_fst(simres.varka,path=file.fst)
} else {
    simres.varka <- read_fst(file.fst)
}
```

```{r,eval=TRUE}
simres.varka |> findCovs(by="KASCALE")

ggplot(simres.varka[simres.varka$EVID==2,],aes(TIME,PRED,colour=factor(KASCALE)))+geom_line()+labs(colour="Fold absorption prolongation")
```

<!-- ## Using NMsim to validate reimplementations of models -->
